{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b36b9a84-8c76-466b-9349-5cd94cca84ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T18:39:01.063564Z",
     "start_time": "2025-07-26T18:39:01.047958Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a818aa454ab84d58",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Pytorch的基本元素操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1852ff4d-c890-4c39-99e2-b1219b64d348",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T18:39:02.454713Z",
     "start_time": "2025-07-26T18:39:02.447385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96676bb6-d795-4466-ae9d-585988b344a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T18:36:07.641748Z",
     "start_time": "2025-07-26T18:36:07.630749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9836, 0.7050, 0.8535],\n",
      "        [0.9122, 0.3672, 0.7307],\n",
      "        [0.9996, 0.2987, 0.2410],\n",
      "        [0.8849, 0.9882, 0.5264],\n",
      "        [0.7821, 0.5565, 0.1039]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca5ea4b-e6ae-4f45-806f-c6381167cb2d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "torch.long 是 PyTorch 中的一种数据类型，表示 64 位有符号整数类型。\n",
    "基本信息\n",
    "全称: torch.int64\n",
    "别名: torch.long\n",
    "精度: 64位整数\n",
    "取值范围: -2^63 到 2^63-1\n",
    "内存占用: 每个数值占用8字节"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dea795972a9550e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T13:00:31.431408Z",
     "start_time": "2025-07-26T13:00:31.415458Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x= torch.zeros(5,3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96de4578-8f8e-4639-8fc0-ff1a6c315748",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "张量是深度学习框架（如PyTorch）中的核心数据结构，可以理解为多维数组的泛化概念。\n",
    "张量的关键属性\n",
    "形状（Shape）：描述张量各维度的大小\n",
    "数据类型（dtype）：如 torch.float32、torch.double 等\n",
    "设备（device）：数据存储位置（CPU或GPU）\n",
    "实际应用\n",
    "在深度学习中，张量用来表示：\n",
    "输入数据：如图像（通常为4维：batch_size×channels×height×width）\n",
    "模型参数：如神经网络的权重和偏置\n",
    "输出结果：模型的预测值\n",
    "损失函数值：训练过程中的损失计算\n",
    "张量是PyTorch进行所有数值计算的基础，支持各种数学运算和变换操作。\n",
    "--------------------------------\n",
    "# 0维张量 - 标量\n",
    "scalar = torch.tensor(5)\n",
    "print(f\"0维张量: {scalar}, 形状: {scalar.shape}\")\n",
    "\n",
    "# 1维张量 - 向量\n",
    "vector = torch.tensor([1, 2, 3])\n",
    "print(f\"1维张量: {vector}, 形状: {vector.shape}\")\n",
    "\n",
    "# 2维张量 - 矩阵\n",
    "matrix = torch.tensor([[1, 2], [3, 4]])\n",
    "print(f\"2维张量: {matrix}, 形状: {matrix.shape}\")\n",
    "\n",
    "# 3维张量 - 立方体\n",
    "tensor_3d = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "print(f\"3维张量: {tensor_3d}, 形状: {tensor_3d.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be2b5cb6d23df4c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T13:03:00.516454Z",
     "start_time": "2025-07-26T13:03:00.512955Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.5000, 3.5000])\n"
     ]
    }
   ],
   "source": [
    "#直接通过数据创建张量 \n",
    "x= torch.tensor([2.5,3.5])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6b58a5e8acf7cee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T13:04:59.195370Z",
     "start_time": "2025-07-26T13:04:59.189296Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#通过已有的张量创建相同尺寸的张量 \n",
    "x = x.new_ones(5,3,dtype=torch.double)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4becb99605c2c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T13:15:34.221520Z",
     "start_time": "2025-07-26T13:15:34.218349Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#在 tensor([1., 2., 3.]) 中，数字后面的点（.）表示这些数字是**浮点数（float）**而不是整数（integer）\n",
    "x = torch.tensor([1.0, 2.0, 3.0], dtype=torch.double)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada3455c-c3c3-470f-8be0-d730f754f022",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "利用randn_like方法创建相同尺寸的张量，并且随机初始化张量，并且随机初始化来对其赋值\n",
    "在PyTorch中，\"相同尺寸的张量\"指的是具有**相同形状（shape）**的张量，即在每个维度上都有相同的大小。\n",
    "torch.randn_like 的作用：\n",
    "torch.randn_like() 函数会创建一个与输入张量形状相同的新张量，但填充值是从标准正态分布（均值为0，标准差为1）中随机采样的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e6be17b71b209e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T13:31:32.396083Z",
     "start_time": "2025-07-26T13:31:32.390792Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0], dtype=torch.double)  # 形状为 [3]\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f481abf3a94f7752",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T13:31:39.536862Z",
     "start_time": "2025-07-26T13:31:39.525318Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2113,  1.8213, -0.3036])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn_like(x, dtype=torch.float)  \n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2a4eee54c728155",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T13:35:37.108808Z",
     "start_time": "2025-07-26T13:35:37.105740Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[ 1.9856,  0.3117, -0.6586],\n",
      "        [-1.4092,  0.1598,  1.0222]])\n"
     ]
    }
   ],
   "source": [
    "original = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float)  # 形状: [2, 3]\n",
    "new_tensor = torch.randn_like(original) \n",
    "print(original)\n",
    "print(new_tensor)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cb7f8b76dd827247",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Pytorch 基本运算操作\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a02cde7688948a33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T13:44:53.128859Z",
     "start_time": "2025-07-26T13:44:53.127218Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "y = torch.tensor([4.0, 5.0, 6.0])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "911a7b4cf830d57b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "addition = torch.add(x, y)\n",
    "print(f\"x + y = {addition}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b0392d40c4d1f6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T13:45:07.408524Z",
     "start_time": "2025-07-26T13:45:07.405199Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x * y = tensor([ 4., 10., 18.])\n"
     ]
    }
   ],
   "source": [
    "multiplication = torch.mul(x, y)\n",
    "print(f\"x * y = {multiplication}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6aba0dedef183469",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T13:45:19.484410Z",
     "start_time": "2025-07-26T13:45:19.480466Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x / y = tensor([0.2500, 0.4000, 0.5000])\n"
     ]
    }
   ],
   "source": [
    "division = torch.div(x, y)\n",
    "print(f\"x / y = {division}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c8c2e1-232e-4e6d-8a2d-dc23f9ec1eec",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "基本定义\n",
    "行（Row）：水平方向排列的元素\n",
    "列（Column）：垂直方向排列的元素\n",
    "------------------------------\n",
    "高维张量中的行和列\n",
    "对于更高维度的张量：\n",
    "二维：(行, 列)\n",
    "三维：(深度, 行, 列) 或 (批次, 行, 列)\n",
    "四维：(批次, 通道, 行, 列) （常用于图像处理）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a90f4bd152d8bf91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T13:48:32.197654Z",
     "start_time": "2025-07-26T13:48:32.194007Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8053, 0.6460],\n",
      "        [1.0021, 1.0827],\n",
      "        [1.6562, 0.2575]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3,2)\n",
    "y = torch.rand(3,2)\n",
    "result = torch.empty(3,2)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "583b8db36f1234f8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "66da9e741601e60c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "x - 目标张量\n",
    "[ , ] - 二维索引语法\n",
    "第一个 : - 行索引，: 表示\"所有行\"（等同于 0:3 或 0:）\n",
    "第二个 :2 - 列索引，表示\"从开始到索引2之前\"（即选择索引0和1列）\n",
    "实际效果\n",
    "由于你的张量 x 本身只有2列（索引0和1），所以 x[:,:2] 实际上会选择：\n",
    "所有行（3行）\n",
    "前2列（实际上就是所有列）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4229d6e7c86698c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T14:00:51.479440Z",
     "start_time": "2025-07-26T14:00:51.474518Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3218, 0.3321],\n",
      "        [0.6427, 0.2426],\n",
      "        [0.6676, 0.1330]])\n"
     ]
    }
   ],
   "source": [
    "print(x[:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e8fac5fa1109aef5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T14:03:27.968669Z",
     "start_time": "2025-07-26T14:03:27.965008Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "x[:,0] - 只选择第1列:\n",
      "tensor([0.3218, 0.6427, 0.6676])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nx[:,0] - 只选择第1列:\")\n",
    "print(x[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "256f63a83258976c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T14:03:50.396640Z",
     "start_time": "2025-07-26T14:03:50.393777Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "x[:,1:] - 从第2列开始到末尾:\n",
      "tensor([[0.3321],\n",
      "        [0.2426],\n",
      "        [0.1330]])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nx[:,1:] - 从第2列开始到末尾:\")\n",
    "print(x[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c179764f9ffd9247",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T14:04:25.962470Z",
     "start_time": "2025-07-26T14:04:25.954568Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "x[1:,:] - 从第2行开始到末尾的所有列:\n",
      "tensor([[0.6427, 0.2426],\n",
      "        [0.6676, 0.1330]])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nx[1:,:] - 从第2行开始到末尾的所有列:\")\n",
    "print(x[1:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d875e047-c793-49b6-be6c-293fadac3b3f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "改变张量的形状：torch.view()\n",
    "\n",
    "view() 方法的特点\n",
    "不改变数据：只是改变数据的组织方式（形状）\n",
    "共享内存：返回的张量与原张量共享内存，修改一个会影响另一个\n",
    "元素总数不变：重塑前后的元素总数必须相等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81972e9e0c176e52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T14:11:05.838767Z",
     "start_time": "2025-07-26T14:11:05.834096Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4,4)    # 创建一个4×4的随机张量\n",
    "y = x.view(16)          # 将x重塑为16个元素的一维张量\n",
    "z = x.view(-1,8)        # 将x重塑为若干行8列的张量（-1表示自动推断该维度大小）\n",
    "print(x.size(), y.size(), z.size())  # 打印各个张量的形状"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc8adee-e268-40ef-b3b0-372213e861f1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "x = torch.randn(4,4)\n",
    "创建一个形状为 [4, 4] 的张量（4行4列，共16个元素）\n",
    "数据是从标准正态分布中随机采样得到的\n",
    "y = x.view(16)\n",
    "使用 view() 方法将张量重塑为一维\n",
    "16 表示新的形状为 [16]，即16个元素的一维张量\n",
    "总元素数量保持不变（4×4 = 16）\n",
    "z = x.view(-1,8)\n",
    "-1 是一个特殊值，表示该维度的大小由PyTorch自动推断\n",
    "由于总元素数是16，而第二维度是8，所以第一维度自动推断为2\n",
    "因此新形状为 [2, 8]（2行8列）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e2f4312bbcb48cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T14:11:19.599685Z",
     "start_time": "2025-07-26T14:11:19.594401Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "重塑为一维 y = x.view(16):\n",
      "形状: torch.Size([16])\n",
      "tensor([-1.0516, -1.7043,  0.8973,  0.2150, -0.5220, -0.5844, -2.0523,  1.1386,\n",
      "        -1.5446,  0.6166, -0.1808, -0.4970, -0.6396, -0.1100,  0.8414, -0.2160])\n"
     ]
    }
   ],
   "source": [
    "y = x.view(16)\n",
    "print(\"\\n重塑为一维 y = x.view(16):\")\n",
    "print(f\"形状: {y.shape}\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "374dc4a5901fdd97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T14:10:58.080521Z",
     "start_time": "2025-07-26T14:10:58.074697Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "重塑为二维 z = x.view(-1, 8):\n",
      "形状: torch.Size([2, 8])\n",
      "tensor([[-0.1544,  0.3992,  1.8202, -0.5044,  0.2974, -1.9535,  0.2268,  2.5592],\n",
      "        [-2.0014, -0.6979, -0.0454, -0.5095,  0.6831,  0.9144, -0.6697,  0.3931]])\n"
     ]
    }
   ],
   "source": [
    "z = x.view(-1, 8)\n",
    "print(\"\\n重塑为二维 z = x.view(-1, 8):\")\n",
    "print(f\"形状: {z.shape}\")\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6cb344ced747ccee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T14:11:43.215743Z",
     "start_time": "2025-07-26T14:11:43.210142Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "修改x[0,0]后，y[0]的值: 999.0\n"
     ]
    }
   ],
   "source": [
    "# 验证共享内存\n",
    "x[0, 0] = 999\n",
    "print(f\"\\n修改x[0,0]后，y[0]的值: {y[0]}\")  # 也会变为999"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbfe0a1-eb36-44f7-8f7b-9d493d02f291",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "与 reshape() 的区别\n",
    "虽然 view() 和 reshape() 都可以改变张量形状，但：\n",
    "view() 要求张量在内存中是连续的，否则会报错\n",
    "reshape() 更灵活，如果张量不连续会自动创建副本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb62d8ea0d88f88",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 在神经网络中常见的用法\n",
    "# 将卷积层输出展平为全连接层输入\n",
    "conv_output = torch.randn(32, 64, 8, 8)  # 批次32，通道64，8×8特征图\n",
    "flattened = conv_output.view(32, -1)     # 变为 [32, 64*8*8] = [32, 4096]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "770ae2ecddc11f52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T14:22:16.210798Z",
     "start_time": "2025-07-26T14:22:16.207003Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1076, -0.7009,  1.0098,  1.5055, -0.1857],\n",
      "        [ 2.0886, -1.0067, -0.6668,  0.3669,  1.0423]])\n",
      "tensor([[-1.1076, -0.7009],\n",
      "        [ 1.0098,  1.5055],\n",
      "        [-0.1857,  2.0886],\n",
      "        [-1.0067, -0.6668],\n",
      "        [ 0.3669,  1.0423]])\n"
     ]
    }
   ],
   "source": [
    " #将张量重新组织为指定的列数\n",
    "# x.view(10, -1) 和 x.view(-1, 10) 的区别\n",
    "# 这两种写法的主要区别在于哪个维度被固定，哪个维度被自动推断。\n",
    "x = torch.randn(10)            # 10个元素\n",
    "x_matrixx = x.view(-1,5)        # 变为 [100, 10] 矩阵\n",
    "x_matrix = x.view(5, -1)        # 变为 [10, 100] 矩阵\n",
    "print(x_matrixx)\n",
    "print(x_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5e760d760efe9919",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T14:23:16.404534Z",
     "start_time": "2025-07-26T14:23:16.401770Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始形状: torch.Size([2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个有120个元素的张量\n",
    "x = torch.randn(2, 3, 4, 5)  # 2×3×4×5 = 120个元素\n",
    "print(f\"原始形状: {x.shape}\")  # torch.Size([2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e20b09f3b79851",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 在图像处理中的实际应用\n",
    "# 假设有一批32张RGB图像，每张图像大小为28×28\n",
    "batch_images = torch.randn(32, 3, 28, 28)  # 32张图像，3个通道，28×28像素\n",
    "print(f\"原始形状: {batch_images.shape}\")   # torch.Size([32, 3, 28, 28])\n",
    "\n",
    "# 情况1: x.view(32, -1) - 保持批次大小为32\n",
    "flattened1 = batch_images.view(32, -1)\n",
    "print(f\"view(32, -1) 结果: {flattened1.shape}\")  # torch.Size([32, 2352])\n",
    "# 每张图像被展平为2352个特征 (3×28×28 = 2352)\n",
    "\n",
    "# 情况2: x.view(-1, 2352) - 指定每行有2352个特征\n",
    "flattened2 = batch_images.view(-1, 2352)\n",
    "print(f\"view(-1, 2352) 结果: {flattened2.shape}\")  # torch.Size([32, 2352])\n",
    "# 这种情况和上面相同，因为2352 = 3×28×28\n",
    "\n",
    "# 情况3: x.view(-1, 28) - 指定每行有28个特征\n",
    "try:\n",
    "    flattened3 = batch_images.view(-1, 28)\n",
    "    print(f\"view(-1, 28) 结果: {flattened3.shape}\")  # torch.Size([2688, 28])\n",
    "    # 自动推断第一维度: 32×3×28×28 ÷ 28 = 2688\n",
    "except RuntimeError as e:\n",
    "    print(f\"错误: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4938316efcf67d2a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#在神经网络中的典型用法\n",
    "\n",
    "# 1. 保持批次大小，展平其他维度\n",
    "def forward_method1(self, x):\n",
    "    # x.shape = [batch_size, channels, height, width]\n",
    "    batch_size = x.size(0)\n",
    "    x = x.view(batch_size, -1)  # 展平为 [batch_size, features]\n",
    "    return x\n",
    "\n",
    "# 2. 固定特征维度，自动推断批次大小\n",
    "def forward_method2(self, x):\n",
    "    # 假设我们知道展平后应该有1000个特征\n",
    "    x = x.view(-1, 1000)  # 展平为 [batch_size, 1000]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ac5404f3d46c2a0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "关键要点\n",
    "-1 的位置决定哪个维度被自动推断\n",
    "固定维度的值决定了张量的组织方式\n",
    "元素总数必须保持不变\n",
    "在实际应用中，通常第一维度是批次大小，需要保持不变\n",
    "总结\n",
    "x.view(100, -1): 保持第一维度为100，自动计算第二维度\n",
    "x.view(-1, 100): 自动计算第一维度，保持第二维度为100\n",
    "选择哪种方式取决于你的具体需求，比如在神经网络中通常需要保持批次大小不变，所以更常用 x.view(batch_size, -1) 的形式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "793bd1f7227f9afa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T14:30:57.695756Z",
     "start_time": "2025-07-26T14:30:57.691553Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3506])\n",
      "-0.35058459639549255\n"
     ]
    }
   ],
   "source": [
    "#如果张量中只有一个元素，可以用.item（）将值取出，作为python number\n",
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85301d3d25abea0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8d38893-29e7-4a09-941f-b8d16dd211f5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### 关于Torch Tensor和Numpy和 python array之间的相互转换"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dc4f55-40cb-437e-8008-91d1208c6420",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "1. Tensor 转换为 NumPy 数组\n",
    "使用 .numpy() 方法将Tensor转换为NumPy数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30afbd3bb3263d1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T14:44:51.079115Z",
     "start_time": "2025-07-26T14:44:51.077121Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "print(b)  # 输出: [1. 1. 1. 1. 1.]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f418d8-e159-4d7e-af50-75593f086a98",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "2. NumPy 数组转换为 Tensor\n",
    " torch.from_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8dd47b4455f6e76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T14:46:04.253328Z",
     "start_time": "2025-07-26T14:46:04.248861Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "numpy_array = np.array([1, 2, 3])\n",
    "tensor_from_numpy = torch.from_numpy(numpy_array)\n",
    "print(tensor_from_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ab154f-6676-46e9-9c89-29887fddb84e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "3. 共享内存特性\n",
    "Torch Tensor和NumPy数组之间的一个重要特性是它们共享内存："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90de2d0dd3e87de",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)        # 输出: tensor([1., 1., 1., 1., 1.])\n",
    "b = a.numpy()\n",
    "print(b)        # 输出: [1. 1. 1. 1. 1.]\n",
    "\n",
    "# 修改Tensor会影响NumPy数组\n",
    "a.add_(1)\n",
    "print(a)        # 输出: tensor([2., 2., 2., 2., 2.])\n",
    "print(b)        # 输出: [2. 2. 2. 2. 2.]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cb11da-a51d-49df-bd77-ee77f14b6f33",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Torch Tensor 与 Python 列表的转换\n",
    "1. Tensor 转换为 Python 列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476fc98cb5fd0f7a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 使用 .tolist() 方法将Tensor转换为Python列表\n",
    "a = torch.tensor([1, 2, 3])\n",
    "python_list = a.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a4d843-7ebb-4a40-b7f9-457492d425bf",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "2. Python 列表转换为 Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c532d3bdad5bde97",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 使用 torch.tensor() 或 torch.Tensor() 将Python列表转换为Tensor\n",
    "python_list = [1, 2, 3]\n",
    "a = torch.tensor(python_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fab82fe-249e-476f-a38d-941d9406bc5e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**重要注意事项**\n",
    "共享内存: Torch Tensor和NumPy数组共享底层内存，修改一个会影响另一个\n",
    "数据类型一致性: 转换时要注意数据类型的匹配\n",
    "设备兼容性: 在GPU上的Tensor不能直接转换为NumPy数组，需要先移动到CPU\n",
    "这些转换功能使得PyTorch能够与Python生态系统中的其他库（如NumPy、Pandas等）很好地集成，方便数据处理和模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb02842-9a91-43c1-874c-086ae3956805",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "关于Cuda Tensor:Tensors可以用.to()方法移动到任意设备上\n",
    "是 Mac没法用 CUDA/NVIDIA，加速方式需用 MPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "716a0efe8d983a4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T15:27:28.587939Z",
     "start_time": "2025-07-26T15:27:28.584093Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.backends.mps.is_available())\n",
    "print(torch.backends.mps.is_built())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a8d9c3-e0b6-4e65-8038-903b4e51aecc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### 主要区别：\n",
    "设备检查：\n",
    "CUDA: torch.cuda.is_available()\n",
    "MPS: torch.backends.mps.is_available()\n",
    "设备定义：\n",
    "CUDA: torch.device(\"cuda\")\n",
    "MPS: torch.device(\"mps\")\n",
    "功能：\n",
    "MPS 在 macOS 上提供了类似于 CUDA 的 GPU 加速功能\n",
    "对于大多数 PyTorch 操作，MPS 和 CUDA 的使用方式非常相似\n",
    "注意事项：\n",
    "你需要安装支持 MPS 的 PyTorch 版本\n",
    "某些操作在 MPS 上可能不如在 CUDA 上成熟或快速\n",
    "你可以通过运行你笔记本中的检查代码来确认 MPS 可用性：\n",
    "\n",
    " MPS (Metal Performance Shaders) 不支持 float64 (double) 数据类型。\n",
    " 在 macOS 上使用 MPS 时，需要使用 float32 数据类型。以下是修复后的代码："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16af9496-d99f-48f1-95d0-7af1f41e1fe5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### 总结\n",
    "GPU 是通用概念，指图形处理单元，现在广泛用于并行计算\n",
    "MPS 是苹果公司为Apple Silicon设备提供的高性能计算框架\n",
    "两者都能显著加速深度学习计算，但适用平台不同\n",
    "在PyTorch中，它们提供了相似的API，使得代码可以在不同平台上移植\n",
    "MPS有一些特殊限制（如不支持float64），需要特别处理\n",
    "选择使用哪种技术主要取决于你的硬件平台：NVIDIA GPU使用CUDA，Apple Silicon使用MPS，其他情况使用CPU。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "135b6eb58383174",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T15:50:20.452562Z",
     "start_time": "2025-07-26T15:50:20.437433Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original x: tensor([[ 0.5558,  1.1701,  0.9447],\n",
      "        [ 0.7543,  0.7514,  0.5123],\n",
      "        [ 2.3072,  1.3961, -0.0764],\n",
      "        [-0.6867,  0.0776, -0.0716],\n",
      "        [ 0.6185,  0.5575,  0.2268]])\n",
      "Using device: mps\n",
      "Result on MPS: tensor([[1.5558, 2.1701, 1.9447],\n",
      "        [1.7543, 1.7514, 1.5123],\n",
      "        [3.3072, 2.3961, 0.9236],\n",
      "        [0.3133, 1.0776, 0.9284],\n",
      "        [1.6185, 1.5575, 1.2268]], device='mps:0')\n",
      "Result moved to CPU with float32 dtype: tensor([[1.5558, 2.1701, 1.9447],\n",
      "        [1.7543, 1.7514, 1.5123],\n",
      "        [3.3072, 2.3961, 0.9236],\n",
      "        [0.3133, 1.0776, 0.9284],\n",
      "        [1.6185, 1.5575, 1.2268]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 首先定义 x 变量\n",
    "x = torch.randn(5, 3)  # 创建一个 5x3 的随机张量\n",
    "print(f\"Original x: {x}\")\n",
    "\n",
    "# 检查是否可以使用 MPS (适用于 macOS 上的 Apple Silicon)\n",
    "if torch.backends.mps.is_available():\n",
    "    # 定义设备对象，这里指 MPS 即使用 GPU\n",
    "    device = torch.device(\"mps\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # 直接在 GPU 上创建一个 tensor\n",
    "    y = torch.ones_like(x, device=device)\n",
    "    # 将 x 移动到 GPU 上（y 已经在 GPU 上了）\n",
    "    x_device = x.to(device)\n",
    "    z = x_device + y\n",
    "    print(f\"Result on MPS: {z}\")\n",
    "    # 也把 z 移动到 CPU 上面，并同时指定张量元素的数据类型\n",
    "    # MPS 不支持 float64，所以使用 float32\n",
    "    print(f\"Result moved to CPU with float32 dtype: {z.to('cpu', torch.float32)}\")\n",
    "else:\n",
    "    # 如果 MPS 不可用，则在 CPU 上执行\n",
    "    print(\"MPS not available, running on CPU\")\n",
    "    y = torch.ones_like(x)\n",
    "    z = x + y\n",
    "    print(f\"Result on CPU: {z}\")\n",
    "    # 在 CPU 上可以使用 float64 (double)\n",
    "    print(f\"Result with double dtype: {z.to(torch.double)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llm-env)",
   "language": "python",
   "name": "llm-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
