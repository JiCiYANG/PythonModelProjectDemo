{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f34daf48-75c2-4ea5-bed9-94b3c00eac31",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "在深度学习中，维度（Dimensions）是一个非常重要的概念，特别是在处理张量（Tensor）数据时。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8279d2-063a-4154-ad41-8997d6c7344c",
   "metadata": {},
   "source": [
    "**基本维度表示 在PyTorch中，张量通常遵循以下维度格式：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-07-27T09:05:46.002598Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 在导入语句之后添加设备定义\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "830b73702e943dd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T09:08:31.762388Z",
     "start_time": "2025-07-27T09:08:31.756319Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "张量形状: torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# 常见的图像数据维度格式 [N, C, H, W]\n",
    "# N (Batch Size): 批次大小 表示一次处理xx张图像\n",
    "# C (Channels): 通道数\n",
    "# H (Height): 图像高度\n",
    "# W (Width): 图像宽度\n",
    "\n",
    "# 示例：\n",
    "batch_size = 64\n",
    "image_tensor = torch.randn(64, 1, 28, 28)  # FashionMNIST数据形状\n",
    "print(f\"张量形状: {image_tensor.shape}\")  # 输出: torch.Size([64, 1, 28, 28])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07706613-0fb7-4b42-b9ea-14fda424ef67",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### 通道（Channels）的数量取决于图像的类型和应用场景。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c03749d-9642-4403-b7df-6b2f7bcaeaa3",
   "metadata": {},
   "source": [
    "1. 灰度图像 (Grayscale)\n",
    "通道数: 1\n",
    "\n",
    "例子: FashionMNIST, MNIST\n",
    "数据形状: [N, 1, H, W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41974bb4769554ef",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-07-27T09:05:49.232075Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "灰度图像形状: torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# 灰度图像示例\n",
    "grayscale_image = torch.randn(64, 1, 28, 28)  # FashionMNIST\n",
    "print(f\"灰度图像形状: {grayscale_image.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff53ae0-0714-4215-a644-fc087b5e4faf",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "2. 彩色图像 (RGB)\n",
    "通道数: 3\n",
    "通道含义: Red (红), Green (绿), Blue (蓝)\n",
    "\n",
    "例子: CIFAR-10, ImageNet\n",
    "数据形状: [N, 3, H, W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ef85a90ae7943e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T09:05:52.856719Z",
     "start_time": "2025-07-27T09:05:52.849457Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB图像形状: torch.Size([32, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# RGB彩色图像示例\n",
    "rgb_image = torch.randn(32, 3, 32, 32)  # CIFAR-10\n",
    "print(f\"RGB图像形状: {rgb_image.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb40790f-262a-45ed-ad52-ab8788fe650e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "3. RGBA图像\n",
    "通道数: 4\n",
    "通道含义: Red, Green, Blue, Alpha (透明度)\n",
    "数据形状: [N, 4, H, W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26810a8292502f7d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 深度学习中的常见通道数\n",
    "# 不同数据集的典型通道数\n",
    "datasets_channels = {\n",
    "    \"MNIST\": 1,           # 手写数字，灰度\n",
    "    \"FashionMNIST\": 1,    # 服装图像，灰度\n",
    "    \"CIFAR-10\": 3,        # 彩色小图像，RGB\n",
    "    \"CIFAR-100\": 3,       # 彩色小图像，RGB\n",
    "    \"ImageNet\": 3,        # 彩色大图像，RGB\n",
    "    \"PASCAL VOC\": 3,      # 彩色图像，RGB\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecaa592-5080-4db2-a421-f02bf2ce0930",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### 维度的变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5276aab0fd3910e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 展平操作\n",
    "x = torch.randn(64, 1, 28, 28)\n",
    "flattened = x.view(64, -1)  # 展平为 [64, 784]\n",
    "# 或使用s flatten\n",
    "flattened = torch.flatten(x, start_dim=1)  # 结果相同\n",
    "\n",
    "# 维度转置\n",
    "x = torch.randn(64, 3, 28, 28)\n",
    "transposed = x.permute(0, 2, 3, 1)  # 转换为 [64, 28, 28, 3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22be04d-57e4-458b-8e59-2d48aa1c1105",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### 2. 维度增加和减少"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7d6c34b7cc287b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 增加维度\n",
    "x = torch.randn(64, 28, 28)\n",
    "expanded = x.unsqueeze(1)  # 变为 [64, 1, 28, 28]\n",
    "\n",
    "# 减少维度\n",
    "x = torch.randn(64, 1, 28, 28)\n",
    "squeezed = x.squeeze(1)  # 变为 [64, 28, 28]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5fe5635671539d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 不同数据集的典型维度\n",
    "datasets_info = {\n",
    "    \"MNIST\": {\"shape\": \"[N, 1, 28, 28]\", \"description\": \"手写数字，灰度\"},\n",
    "    \"FashionMNIST\": {\"shape\": \"[N, 1, 28, 28]\", \"description\": \"服装图像，灰度\"},\n",
    "    \"CIFAR-10\": {\"shape\": \"[N, 3, 32, 32]\", \"description\": \"彩色小图像，RGB\"},\n",
    "    \"CIFAR-100\": {\"shape\": \"[N, 3, 32, 32]\", \"description\": \"彩色小图像，RGB\"},\n",
    "    \"ImageNet\": {\"shape\": \"[N, 3, 224, 224]\", \"description\": \"彩色大图像，RGB\"}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35429991-f527-4b79-87c1-759226bc951d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### 维度在神经网络中的应用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c538395c-0e6b-4c59-9dd9-7cb0448fcee2",
   "metadata": {},
   "source": [
    "1. 全连接层维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13e39354f540cf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T09:12:27.460253Z",
     "start_time": "2025-07-27T09:12:27.454231Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 输入维度转换示例\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()  # [N, 1, 28, 28] -> [N, 784]\n",
    "        self.linear_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),   # 输入784维，输出512维\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),     # 输入512维，输出512维\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)       # 输入512维，输出10维(分类数)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56df058b-bb99-4dc9-836c-218379292a60",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "2. 卷积层维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5ecb2edef964e57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T09:12:29.168839Z",
     "start_time": "2025-07-27T09:12:29.160215Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 卷积层的输入输出维度\n",
    "conv_layer = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
    "# 输入: [N, 1, 28, 28]\n",
    "# 输出: [N, 32, 26, 26] (由于3x3卷积核，无padding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f05ea36da65e27fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T09:12:39.557108Z",
     "start_time": "2025-07-27T09:12:39.467416Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 使用示例\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m train_dataloader = DataLoader(\u001b[43mtraining_data\u001b[49m, batch_size=\u001b[32m64\u001b[39m)\n\u001b[32m     10\u001b[39m check_dimensions(train_dataloader)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# 输出示例:\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Input shape: torch.Size([64, 1, 28, 28])\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Label shape: torch.Size([64])\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'training_data' is not defined"
     ]
    }
   ],
   "source": [
    "# 在训练过程中检查维度\n",
    "def check_dimensions(dataloader):\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        print(f\"Input shape: {batch_x.shape}\")\n",
    "        print(f\"Label shape: {batch_y.shape}\")\n",
    "        break\n",
    "\n",
    "# 使用示例\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "check_dimensions(train_dataloader)\n",
    "# 输出示例:\n",
    "# Input shape: torch.Size([64, 1, 28, 28])\n",
    "# Label shape: torch.Size([64])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
