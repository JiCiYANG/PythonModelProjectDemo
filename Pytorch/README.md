## 1. PyTorch基础概念

### Dataset和DataLoader
- `Dataset`类的作用：存储和管理数据样本及标签
- `DataLoader`类的作用：提供批量处理、数据打乱和并行加载功能
- 数据预处理转换（如`ToTensor()`）

### 张量操作
- 张量的基本操作和形状理解：`[N, C, H, W]`格式
- 不同类型图像的通道数（灰度图1通道，RGB图3通道）
- 设备管理（CPU/GPU/MPS）及`.to(device)`方法

## 2. 神经网络构建

### 模型定义
- 继承`nn.Module`创建自定义模型
- 使用`nn.Sequential`构建网络层序列
- 理解前向传播方法`forward()`
- 线性层`nn.Linear`和激活函数`nn.ReLU`的使用

### 网络层概念
- 展平层`nn.Flatten`将2D图像转为1D向量
- 全连接层的输入输出维度计算
- 分类任务的输出层设计（10个类别对应10个输出）

## 3. 训练流程核心组件

### 损失函数
- `nn.CrossEntropyLoss`交叉熵损失函数的原理和使用
- 损失函数在分类任务中的作用
- 梯度计算和反向传播`loss.backward()`

### 优化器
- 随机梯度下降(SGD)优化算法原理
- 学习率的概念和设置
- 参数更新`optimizer.step()`和梯度清零`optimizer.zero_grad()`

## 4. 训练和评估过程

### 训练循环
- 模型训练模式`model.train()`
- 批处理数据的迭代处理
- 损失值监控和打印

### 测试评估
- 模型评估模式`model.eval()`
- 禁用梯度计算`torch.no_grad()`
- 准确率计算方法
- 平均损失的统计方法

## 5. 实用技能

### 硬件加速
- 设备检测和选择（CPU/GPU/MPS）
- 确保模型和数据在同一设备上

### 代码组织
- 训练函数和测试函数的封装
- 训练周期(Epoch)的概念和实现
- 结果输出和日志记录
